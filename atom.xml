<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Mk Zang]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://zyq001.github.io/"/>
  <updated>2015-09-01T17:48:43.222Z</updated>
  <id>http://zyq001.github.io/</id>
  
  <author>
    <name><![CDATA[Mk Zang]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[列式Parquet与行式Avro，对比Benchmarks性能测试]]></title>
    <link href="http://zyq001.github.io/2015/09/01/%E5%88%97%E5%BC%8FParquet%E4%B8%8E%E8%A1%8C%E5%BC%8FAvro%EF%BC%8C%E5%AF%B9%E6%AF%94Benchmarks%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    <id>http://zyq001.github.io/2015/09/01/列式Parquet与行式Avro，对比Benchmarks性能测试/</id>
    <published>2015-08-31T16:40:09.000Z</published>
    <updated>2015-09-01T17:48:43.222Z</updated>
    <content type="html"><![CDATA[<h2 id="关于Parquet">关于Parquet</h2><p>  Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，细节请参考[[这里|<a href="http://parquet.apache.org/documentation/latest/]]。" target="_blank" rel="external">http://parquet.apache.org/documentation/latest/]]。</a></p>
<h3 id="列式存储">列式存储</h3><a id="more"></a>
<p>  列式存储和行式存储相比有哪些优势呢？</p>
<ul>
<li>可以跳过不符合条件的数据，只读取需要的数据，降低IO数据量。</li>
<li>压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样的，可以使用更高效的压缩编码（例如Run Length Encoding和Delta Encoding）进一步节约存储空间。</li>
<li>只读取需要的列，支持向量运算，能够获取更好的扫描性能。</li>
</ul>
<h3 id="适配多种计算框架">适配多种计算框架</h3><p>Parquet是语言无关的，而且不与任何一种数据处理框架绑定在一起，适配多种语言和组件，能够与Parquet配合的组件有：</p>
<ul>
<li>查询引擎: Hive, Impala, Pig, Presto, Drill, Tajo, HAWQ, IBM Big SQL</li>
</ul>
<ul>
<li>计算框架: MapReduce, Spark, Cascading, Crunch, Scalding, Kite</li>
</ul>
<ul>
<li>数据模型: Avro, Thrift, Protocol Buffers, POJOs</li>
</ul>
<h3 id="性能">性能</h3><p>Parquet就是基于Google的<strong>Dremel</strong>系统的数据模型和算法实现的。核心思想是使用“record shredding and assembly algorithm”来表示复杂的嵌套数据类型，同时辅以按列的高效压缩和编码技术，实现降低存储空间，提高IO效率，降低上层应用延迟。</p>
<p>Parquet列式存储带来的性能上的提高在业内已经得到了充分的认可，特别是当你们的表非常宽（column非常多）的时候，Parquet无论在资源利用率还是性能上都优势明显。具体的性能指标详见参考文档。</p>
<p>Spark已经将Parquet设为默认的文件存储格式，Cloudera投入了很多工程师到Impala+Parquet相关开发中，Hive/Pig都原生支持Parquet。Parquet现在为Twitter至少节省了1/3的存储空间，同时节省了大量的表</p>
<p>扫描和反序列化的时间。这两方面直接反应就是节约成本和提高性能（详见[[YaqiangZang#benchmark|benchmark]]）。</p>
<h2 id="benchmark">benchmark</h2><p>以邮箱的展示日志为例，比较了Avro和Parquet两种存储格式的性能：camus-2015/05/24的日志，5,361,809条记录，ns005，hadoop2.4，Spark1.3.1。结果见下图：</p>
<p><img src="/images/parquetBenchMarkRest.png" alt="测试结果"> </p>
<p>备注：1. 测试代码详见github - <a href="https://github.com/zyq001/AvroParquetBenchMark" target="_blank" rel="external">AvroParquetBenchMark</a>   2. 读取Avro是新老API性能差距较大，目前还未找到原因。</p>
<h2 id="与Avro">与Avro</h2><p>之前新统计系统（Quipu）的日志都是用Avro做序列化和存储，鉴于Parquet的优势和对Avro的兼容，将HDFS上的存储格式改为Paruqet，并且只需做很小的改动就用原读取Avro的API读取Parquet，单列查询效率可</p>
<p>以提高近一个数量级。</p>
<h2 id="Schema">Schema</h2><p>Parquet文件尾部存储了文件的元数据信息和统计信息，自描述的，方便解析。仍沿用原Avro的schema。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="关于Parquet">关于Parquet</h2><p>  Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，细节请参考[[这里|<a href="http://parquet.apache.org/documentation/latest/]]。">http://parquet.apache.org/documentation/latest/]]。</a></p>
<h3 id="列式存储">列式存储</h3>]]>
    
    </summary>
    
      <category term="HDFS" scheme="http://zyq001.github.io/tags/HDFS/"/>
    
      <category term="Spark" scheme="http://zyq001.github.io/tags/Spark/"/>
    
      <category term="parquet" scheme="http://zyq001.github.io/tags/parquet/"/>
    
      <category term="列式存储" scheme="http://zyq001.github.io/tags/%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
      <category term="Hadoop" scheme="http://zyq001.github.io/categories/Hadoop/"/>
    
      <category term="HDFS" scheme="http://zyq001.github.io/categories/Hadoop/HDFS/"/>
    
      <category term="存储格式" scheme="http://zyq001.github.io/categories/Hadoop/HDFS/%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    
      <category term="Parquet" scheme="http://zyq001.github.io/categories/Hadoop/HDFS/%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/Parquet/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[git常见问题备忘]]></title>
    <link href="http://zyq001.github.io/2015/08/30/git%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%A4%87%E5%BF%98/"/>
    <id>http://zyq001.github.io/2015/08/30/git常见问题备忘/</id>
    <published>2015-08-30T07:15:46.000Z</published>
    <updated>2015-09-01T17:23:15.101Z</updated>
    <content type="html"><![CDATA[<h3 id="1,github_changes_not_staged_for_commit">1,github changes not staged for commit</h3><p>   Git在未进行commit操作之前，存在三种状态：Untracked files，<br>   Changes not staged for commit及Changes to be committed，每种状态之间可以随意进行互相转换。</p>
<p>   -Changes not staged for </p>
<p>   commit”状态，表明文件已经修改，但是还没有放入暂存区域，也就是没生成快照。<br>   如果现在进行commit操作，只是将修改之前的文件快照提交到了git目录，<br>   只有暂存区域的文件（即：文件状态为“Changes to be committed”）才会被提交。<br>   正如提示，通过“git add README.txt”命令将已修改文件更新到暂存区域中，<br>   如果想撤销修改，可以使用“git checkout – README.txt”命令。<br>   <a id="more"></a><br>   如果通过git add . 或者 git add * 或者git add 文件名都依然处于not staged状态，那么需要考虑项目中是否有submodule（子模块），<br>   如果有，需要现在submodule中 add &amp; commit，再在主项目中git add才能把最新修改提交到本地版本库。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="1,github_changes_not_staged_for_commit">1,github changes not staged for commit</h3><p>   Git在未进行commit操作之前，存在三种状态：Untracked files，<br>   Changes not staged for commit及Changes to be committed，每种状态之间可以随意进行互相转换。</p>
<p>   -Changes not staged for </p>
<p>   commit”状态，表明文件已经修改，但是还没有放入暂存区域，也就是没生成快照。<br>   如果现在进行commit操作，只是将修改之前的文件快照提交到了git目录，<br>   只有暂存区域的文件（即：文件状态为“Changes to be committed”）才会被提交。<br>   正如提示，通过“git add README.txt”命令将已修改文件更新到暂存区域中，<br>   如果想撤销修改，可以使用“git checkout – README.txt”命令。<br>]]>
    
    </summary>
    
      <category term="changes not staged" scheme="http://zyq001.github.io/tags/changes-not-staged/"/>
    
      <category term="git" scheme="http://zyq001.github.io/tags/git/"/>
    
      <category term="github" scheme="http://zyq001.github.io/tags/github/"/>
    
      <category term="问题" scheme="http://zyq001.github.io/tags/%E9%97%AE%E9%A2%98/"/>
    
      <category term="git" scheme="http://zyq001.github.io/categories/git/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java, 基础（面试题）总结（分享-交流）]]></title>
    <link href="http://zyq001.github.io/2015/04/29/Java-%E5%9F%BA%E7%A1%80%EF%BC%88%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%89%E6%80%BB%E7%BB%93%EF%BC%88%E5%88%86%E4%BA%AB-%E4%BA%A4%E6%B5%81%EF%BC%89/"/>
    <id>http://zyq001.github.io/2015/04/29/Java-基础（面试题）总结（分享-交流）/</id>
    <published>2015-04-28T18:02:42.000Z</published>
    <updated>2015-09-01T17:27:20.838Z</updated>
    <content type="html"><![CDATA[<h3 id="1-_Finally，final，finalize">1. Finally，final，finalize</h3><ul>
<li><p>Finally：<br>  释放资源（内存之外的，打开的文件、连接、屏幕上的图形，，）</p>
<ul>
<li>总会执行</li>
<li>非后台线程结束，后台线程被强关，不会执行finally</li>
<li>当try和catch中有return时，finally在return之后执行，但是返回值不会改变（finally中不会改变已保存的返回结果）</li>
<li>finally中最好不要包含return，否则程序会从finally中退出，返回值不是try或catch中保存的返回值。</li>
</ul>
</li>
<li><p>final：<br>  基本数据类型：不可更改<br>  类：不可继承<br>  对象：引用不可变，对象内容可变</p>
</li>
<li><p>finalze：<br>回收前调用，不适合用来清理或释放资源。对象免死最后机会！保证会被调用，但不保证会执行完(在低优先级线程中执行)</p>
<a id="more"></a>
</li>
</ul>
<h3 id="2-_数据在各个网络层之间是怎么传输的？">2. 数据在各个网络层之间是怎么传输的？</h3><ul>
<li>数据在各层之间的单位都是不一样的，</li>
<li>在物理层数据的单位称为比特（bit）；在数据链路层，数据的单位称为帧（frame）；</li>
<li>在网络层，数据的单位称为数据包（packet）；传输层，数据的单位称为数据段（segment）。 </li>
</ul>
<h3 id="3-_Hashtable、HashMap">3. Hashtable、HashMap</h3><ul>
<li><p>Hashtable 与 HashMap类似,但是主要有7点不同。</p>
<ol>
<li>HashTable的方法是同步的，HashMap未经同步，如Vector和ArrayList一样。</li>
<li>HashTable不允许null，key和value都不可以,HashMap允许null值，key和value都可以。HashMap允许 key值只能由一个null</li>
<li>HashTable有一个contains(Object value)功能和containsValue(Object value)功能一样。</li>
<li>遍历的时候，HashTable使用Enumeration，HashMap使用Iterator。</li>
<li>HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。</li>
<li>哈希值的使用不同，HashTable直接使用对象的hashCode。</li>
<li>Hashtable继承自Dictionary类，实现了Map接口。而HashMap是继承自AbstractMap，实现了Map接口。</li>
</ol>
</li>
<li><p><strong>HashMap:</strong><br>一个数组，hash（h）决定位置，<br> 冲突使用链表法：单向–Entry对象（保存final key，value，next指针，hash值），遍历比较hash值<br> Collections.synchronizedMap(hashmap)来构造一个线程安全的map，与Hashtable几乎一样<br> 扩容：先插入再判断是否扩容</p>
</li>
<li><p><strong>Hashtable：</strong> 直接使用对象hash值，对跟线程安全相关的方法和步骤加Syncrolized</p>
</li>
<li><p><strong>LinkedHashMap：</strong><br>继承HashMap， 重写Entry类，before，after两个指针，保存插入顺序或者访问顺序（可指定）</p>
</li>
<li><strong>HashSet：</strong><br>持有一个HashMap</li>
</ul>
<ul>
<li><strong>ConcurrentHashMap:</strong>  <ul>
<li>两个数组Segment[] 和HashEntry[]    </li>
<li><strong>Segment：</strong> extends ReentrantLock, 一种可重入锁，持有一个数组HashEntry[]，可以通过concurrencylevel指定Segment数组长度  </li>
<li><strong>HashEntry：</strong> hash，key，value，next</li>
<li><strong>读不需要锁</strong>，读到空时加锁重读</li>
<li><strong>扩容：</strong>支队某个Segment的HashEntry[]扩容，先判断是否扩容再插入</li>
<li><strong>size（）</strong>：先尝试两次锁，判断modCount是否变化再决定是否加锁。 </li>
</ul>
</li>
<li><strong>CopyOnWriteArrayList:</strong> 适合多读少写，只保证最终一致性，不保证实时一致性<ul>
<li>加锁–&gt;拷贝数据–&gt;改、写–&gt;赋值回去–&gt;解锁</li>
<li>用的ReentrantLock，读无需锁，可能读到旧数据。    </li>
</ul>
</li>
<li><strong>TreeMap：</strong>红黑树，可自定义顺序</li>
<li><strong>TessSet：</strong>TreeMap</li>
</ul>
<h3 id="4-_GET，POST区别？">4. GET，POST区别？</h3><ul>
<li><p><strong>基础知识：</strong>  Http的请求格式如下。<br><strong><request line\=""></request></strong>   主要包含三个信息：<br>1、请求的类型（GET或POST），2、要访问的资源（如res\img\a.jif），3、Http版本（http/1.1）<br><strong><header\></header\></strong>  用来说明服务器要使用的附加信息<br><strong><blank line\=""></blank></strong>  这是Http的规定，必须空一行<br><strong>[<request-body\>]</request-body\></strong>  请求的内容数据   </p>
</li>
<li><p><strong>区别：</strong><br>1、Get是从服务器端获取数据，Post则是向服务器端发送数据。<br>2、在客户端，Get方式通过URL提交数据，在URL地址栏可以看到请求消息，该消息被编码过；Post数据则是放在Html header内提交。<br>3、对于Get方式，服务器端用Request.QueryString获取变量的值；对用Post方式，服务器端用Request.Form获取提交的数据值。<br>4、Get方式提交的数据最多1024字节，而Post则没有限制。<br>5、Get方式提交的参数及参数值会在地址栏显示，不安全，而Post不会，比较安全。</p>
</li>
</ul>
<h3 id="5-_网游服务器用TCP还是UDP">5. 网游服务器用TCP还是UDP</h3><ul>
<li>UDP：多用，一个socket，加自己的可靠协议，延迟要求高</li>
<li>TCP：承载链接数多，500以上有压力，魔兽世界用TCP，1000延迟照样玩</li>
<li>HTTP/HTTPS：由客户端间歇性的发起无状态的查询，并且偶尔发生延迟是可以容忍</li>
</ul>
<h3 id="6-_关于JAVA内存模型，一个对象（两个属性，四个方法）实例化100次，现在内存中的存储状态，几个对象，几个属性，几个方法。">6. 关于JAVA内存模型，一个对象（两个属性，四个方法）实例化100次，现在内存中的存储状态，几个对象，几个属性，几个方法。</h3><ul>
<li>由于JAVA中new出来的对象都是放在堆中，所以如果要实例化100次，将在堆中产生100个对象，  </li>
</ul>
<ul>
<li>一般对象与其中的属性、方法都属于一个整体，但如果 属性和方法是静态的，就是用static关键字声明的，那么属于类的属性和方法永远只在内存中存在一份。</li>
</ul>
<h3 id="7-_红黑树的好处、AVL_树">7.  红黑树的好处、AVL 树</h3><ul>
<li><p><strong>红黑树性质：</strong>  </p>
<ul>
<li>根节点是黑色的；  </li>
<li>非黑即红；  </li>
<li>叶节点（空节点）是黑色的；  </li>
<li>父节点是红色的，则其孩子节点必须是黑色的；  </li>
<li>从某一个节点到叶节点的所有路径，其黑色节点数目相同。 </li>
</ul>
</li>
<li><p><strong>红黑树好处：</strong>  </p>
<ul>
<li>红黑树是许多“平衡的”查找树中的一种，它能保证在最坏情况 下，基本的动态集合操作时间为 O(lgn)。   </li>
<li>红黑树并不追求完全平衡，它只要求部分的达到平衡要求，降低 了对旋转的要求，从而提高了性能。由于它的设计，任何不平衡都会在三次旋转之内解决。</li>
<li>红黑树的算法时间复杂度和 AVL相同， 但统计性能比 AVL 树更高。 </li>
<li>AVL 树明显比红黑树逻辑简单的多，但应用得少，应该是增删性能  差一点，增删时需要旋转的次数可能比较多。</li>
</ul>
</li>
</ul>
<h3 id="8-_数组和链表，遍历效率哪个高，为什么（cpu缓存与内存）">8. 数组和链表，遍历效率哪个高，为什么（cpu缓存与内存）</h3><ul>
<li><strong>数组的效率高</strong>，因为数组是连续存储的，即内存地址是连续的，所以在读取数组时，会将连续的内存地址的数据放入缓存中，所以读取数组时相当于是从缓存读取。而链表遍历都是从内存读取，缓存的读取速度要比内存块 100 倍左右。</li>
</ul>
<h3 id="9-_进程间通信,_怎么共享内存">9. 进程间通信, 怎么共享内存</h3><ul>
<li><strong>匿名管道：</strong>单向，只能用于具有亲缘关系的进程间通信，如父 子进程、兄弟进程等，缓冲区大小有限制。 </li>
<li><strong>命名管道：</strong>单向，可以用在任意的两个不同的进程间通信。</li>
<li><strong>信号量：</strong>主要用于同步。</li>
<li><strong>共享内存：</strong>最快的 IPC 机制，一般和信号量一起使用。一个进程创建，其他进程通过映射的形式，将共享内存加入到自己的内存空间中。数据结构：shmid_ds，函数 shmget:可以创建或 打开一块共享内存。 </li>
<li><strong>消息队列：</strong>是消息的链接表，有足够权限的进程可以向队列中 添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了管道只能承载无格式字节流以及缓冲区大小受 限等缺点。 </li>
<li><strong>Socket：</strong>更为一般的进程间通信机制，可用于不同机器之间的进程间通信。</li>
</ul>
<h3 id="10-_Fork_进程时，继承那些：">10. Fork 进程时，继承那些：</h3><ul>
<li><strong>继承</strong>：进程的资格、堆栈、环境、内存、打开文件的描述符、执行时关闭标志、信号控制设定、nice 值、进程调度类别、进程 组号、当前工作目录、根目录、资源限制、控制终端。</li>
<li><strong>独有</strong>：进程号、不同的父进程号、自己的文件描述符和目 录流的拷贝、子进程不继承父进程的进程，正文，数据和其他锁定内存、在 tms 结构中的系统时间、资源使用设定为 0、阻塞信号集初始化为空集、不继承由 timer_create 函数创建的计时器、不继承异步输入和输出。</li>
</ul>
<h3 id="11-_1000_个超大的文件，可能每一个都超过内存，怎么对他们进_行排序和消除冲项，1_个超大怎么排序和消除重项。">11. 1000 个超大的文件，可能每一个都超过内存，怎么对他们进 行排序和消除冲项，1 个超大怎么排序和消除重项。</h3><ul>
<li>读文件，计算hash（%10000），分成更小的文件，重复项肯定在一个文件里，归并的时候去重</li>
</ul>
<h3 id="12-_2_个数组，一个超大数组（10w_记录），一个小一点，几千条，_问怎么找交集。两个数组元素无重复">12. 2 个数组，一个超大数组（10w 记录），一个小一点，几千条， 问怎么找交集。两个数组元素无重复</h3><ul>
<li><strong>bitmap：</strong>bit数组，已bit代表一个数，1表示有，遍历大数组构造bit数组；遍历小数组，看对应位置是否为1</li>
</ul>
<h3 id="13-_StackOverFlow和OutOfMemory分别在什么情况下出现">13. StackOverFlow和OutOfMemory分别在什么情况下出现</h3><ul>
<li><p><strong>StackOverFlow：</strong>一般情况下stack的默认值为128k~256k, -Xss1024m<br>请求栈深度大于允许最大深度，如：深度循环递归</p>
<ul>
<li><strong>OutOfMemory：</strong><br>多线程环境下，能够创建的线程最大内存=物理内存-最大堆内存-最大方法区内存，java虚拟机栈就会因为内存太小无法创建线程而产生OutOfMemoryError<br>大的对象或数组，堆地方不够用<br>运行时常量池（方法区）因无法再添加常量而产生OutOfMemoryError<br>直接内存用光，堆与直接内存&gt;物理内存<br>虚拟机栈动态扩展时无法获得足够内存</li>
</ul>
</li>
</ul>
<h3 id="14-_java虚拟机模型">14. java虚拟机模型</h3><ul>
<li><strong>虚拟机栈：</strong> 方法内存模型，一个方法一个栈帧，包括：局部变量表，操作数栈，动态链接，方法出口，请求栈深度大于允许报StackOverFlow，动态扩展无法申请足够内存，包OOM。-xss设栈容量默认256k？ </li>
</ul>
<ul>
<li><strong>局部变量表：</strong> 所属对象引用，方法参数，局部变量（基本类型，引用）<br>本地方法栈：与虚拟机栈相识，面向本地native方法，hotspot中与虚拟机栈合二为一  </li>
</ul>
<ul>
<li><strong>堆：</strong> 对象实例，数组，类加载完成便可确定对象大小，OOM  </li>
</ul>
<ul>
<li><strong>方法区：</strong> 也有人叫永久代（Permanent Generation）类信息，常量，静态变量等在加载完成后放入方法区，即时编译器编译后的代码。  </li>
</ul>
<ul>
<li><strong>运行常量池</strong>：class文件中的常量池，编译生成的字面量，符号引用（new对象时：先检查此类的符号引用是否加载、解析、初始化过，若否，先加载）；动态性：String.intern</li>
</ul>
<h3 id="15-_虚拟机垃圾回收">15. 虚拟机垃圾回收</h3><ul>
<li><strong>可达性分析:</strong> 从GCroots向下搜索，判断是否有引用可达。  </li>
<li><p><strong>GCroots:</strong><br> 虚拟机栈（本地变量表）中引用的对象，方法区中类静态属性引用的对象，方法区中常量引用的对象，本地方法栈中JNI引用的对象  </p>
</li>
<li><p><strong>强引用：</strong>永远不会回收被引用的对象。<br><strong>软引用SoftRef：</strong>有用但非必需的对象，发生内存溢出异常前将对象列进回收范围中进行第二次回收，如果此次回收还没有足够内存才会抛异常<br><strong>弱引用WeakRef：</strong>非必需对象，只能生存到下一次垃圾回收之前，无论内存是否够，都会回收<br><strong>虚引用PhantomRef：</strong>完全不对生存时间构成影响，也无法通过虚引用来取得一个对象实例</p>
</li>
<li><p><strong>标记整理算法:</strong> 所有存活的对象都向一端移动，然后清理边界以外的内存<br><strong>分代收集：</strong>当前多采用，<br><strong>复制算法:</strong>老年代做担保，新生代分三块一个Eden80％ 两个survivor都是10％</p>
</li>
<li><p><strong>java堆</strong>分成：新生代Eden，老年代(Survivor，两个 from to)<br>   <strong>新生代：</strong>复制算法，<br>   <strong>老年代：</strong>存活率高，适合标记清理或整理。  </p>
</li>
<li><p><strong>Serial:</strong> 复制算法 单线程 client模式默认新生代收集器，stop the world,简单高效<br><strong>ParNew:</strong>  Serial的多线程版本，其他都 server模式首选，只有它能跟CMS搭配<br><strong>Parallel Scavenge:</strong> 关注吞吐量(cpu执行用户)</p>
<ul>
<li><p><strong>并行:</strong> 多个收集线程同时收集</p>
<p><strong>并发:</strong>收集线程和用户线程同时，不一定并行可能交替</p>
</li>
<li><p><strong>方法区(hotspot的永久代) 也可以回收</strong><br><strong>废弃常量</strong>的回收<br><strong>类的回收</strong>: 无对象，classloader已回收，该类对应的class文件没有被引用，且不可通过反射获取该方法</p>
</li>
</ul>
</li>
</ul>
<h3 id="16-_TTL：">16. TTL：</h3><ul>
<li>Time To Live，指定IP包被路由器丢弃之前允许通过的最大网段数量。《TCP/IP详解卷I》路由器会丢弃ttl为0或1的数据包</li>
</ul>
<h3 id="17-_string类_能否继承？如果写一个类_不能被继承_final外_还有什么方法">17. string类 能否继承？如果写一个类 不能被继承  final外 还有什么方法</h3><ul>
<li>不能，因为是final的。  </li>
</ul>
<ul>
<li>还可以把构造函数私有化，单例模式</li>
</ul>
<h3 id="18-_链表的倒转，不倒转可以递归">18. 链表的倒转，不倒转可以递归</h3><h3 id="19-_session和cookie的区别：">19. session和cookie的区别：</h3><ul>
<li><p>session放在服务器，cookie放在客户端 </p>
</li>
<li><p>session不区分路径，在同一个用户在访问一个网站期间，所有的session在任何一个地方都可以访问到。而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不到的。也就是说，同一个用户的cookie，他换了浏览器，就访问不到之前的那个不同牌子的浏览器的cookie了。</p>
</li>
<li><p>session中保存的是对象，cookie中保存的是字符串。 </p>
</li>
<li><p>由于采用服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制来达到保存标识的目的，但实际上它还有其他选择【经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段】。</p>
</li>
</ul>
<h3 id="20-_单例模式线程安全">20.  单例模式线程安全</h3><ul>
<li>静态变量new 对象，类加载时即生成，</li>
<li>加锁：双重检测加锁 不能达到真正的线程安全，1.5之前主要是JIT编译器执行顺序问题.1.6之后可能是指令重排（volatile可解决？）</li>
<li><p>使用私有的静态类来实现：  </p>
<p>``public class Singleton<br>{  </p>
<pre><code>private<span class="keyword"> static</span> class SingletonHolder //私有静态类  
{  
   <span class="keyword"> public</span><span class="keyword"> final</span><span class="keyword"> static</span> Singleton<span class="instruction"> instance </span>=<span class="instruction"> new </span>Singleton(<span class="function">)</span>;  
}  <span class="keyword">
public</span><span class="keyword"> static</span> Singleton<span class="function"> getInstance(</span><span class="function">)</span>  
    {  
<span class="instruction"> return </span>SingletonHolder.instance;  
    }  
}``
</code></pre></li>
</ul>
<ol>
<li>枚举单例</li>
</ol>
<h3 id="21-_序列化接口">21. 序列化接口</h3><ul>
<li>对象持久化，transient：修饰变量，不序列化 </li>
</ul>
<h3 id="22-_删除无头链表的某节点(编程之美3-4)">22. 删除无头链表的某节点(编程之美3.4)</h3><ul>
<li>将下一节点数据复制到该节点，删除下一节点而非该节点</li>
</ul>
<h3 id="23-_JAVA多态">23. JAVA多态</h3><ul>
<li>动态绑定(后期绑定，运行时绑定，前期是编译时绑定)</li>
</ul>
<ol>
<li>指向之类对象的指针，调用子类对象的方法(如果已重写父类方法，否则默认调父类方法)</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="1-_Finally，final，finalize">1. Finally，final，finalize</h3><ul>
<li><p>Finally：<br>  释放资源（内存之外的，打开的文件、连接、屏幕上的图形，，）</p>
<ul>
<li>总会执行</li>
<li>非后台线程结束，后台线程被强关，不会执行finally</li>
<li>当try和catch中有return时，finally在return之后执行，但是返回值不会改变（finally中不会改变已保存的返回结果）</li>
<li>finally中最好不要包含return，否则程序会从finally中退出，返回值不是try或catch中保存的返回值。</li>
</ul>
</li>
<li><p>final：<br>  基本数据类型：不可更改<br>  类：不可继承<br>  对象：引用不可变，对象内容可变</p>
</li>
<li><p>finalze：<br>回收前调用，不适合用来清理或释放资源。对象免死最后机会！保证会被调用，但不保证会执行完(在低优先级线程中执行)</p>]]>
    
    </summary>
    
      <category term="Java" scheme="http://zyq001.github.io/tags/Java/"/>
    
      <category term="面试" scheme="http://zyq001.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Java" scheme="http://zyq001.github.io/categories/Java/"/>
    
      <category term="面试" scheme="http://zyq001.github.io/categories/Java/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
</feed>
